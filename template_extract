import cv2
import numpy as np


def img_detector(img, template):
    # Convert the images to grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)

    # Initialize the akaze detector
    akaze = cv2.AKAZE_create(threshold=0.000001, nOctaves=5, nOctaveLayers=5, diffusivity=1)

    # Detect keypoints and compute descriptors for the images
    kp1, des1 = akaze.detectAndCompute(img_gray, None)
    kp2, des2 = akaze.detectAndCompute(template_gray, None)

    # Convert descriptors to np.float32
    des1 = des1.astype(np.float32)
    des2 = des2.astype(np.float32)

    # Initialize FLANN matcher
    flann = cv2.FlannBasedMatcher()

    # Find potential matches using FLANN matcher
    matches = flann.knnMatch(des1, des2, k=2)

    # Step 3: Filter out incorrect matches using the ratio test
    good_matches = []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            good_matches.append(m)

    # Step 4: Apply RANSAC to filter out incorrect matches
    if len(good_matches) > 5:
        # Convert keypoints to numpy arrays
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

        # Estimate the homography matrix using RANSAC
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

    else:
        return 'Not enough matches found!'

    # Apply the homography to the image to adjust its position and rotation
    img_warped = cv2.warpPerspective(img, M, (template.shape[1], template.shape[0]))

    # Crop the image to remove any black borders
    gray = cv2.cvtColor(img_warped, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)
    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    x, y, w, h = cv2.boundingRect(contours[0])
    img_cropped = img_warped[y:y + h, x:x + w]

    return img_cropped
